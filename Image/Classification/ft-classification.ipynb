{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_file_path': '/home/abhinowo/.cache/huggingface/datasets/downloads/extracted/2d386833a5392a8f531ac73d0dba1975446e11dd81263ffcd76ecae7fe698bf8/train/angular_leaf_spot/angular_leaf_spot_train.107.jpg',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500>,\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"beans\")\n",
    "dataset[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "\n",
    "transform = albumentations.Compose([\n",
    "    albumentations.RandomCrop(width=256, height=256),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(p=0.2),\n",
    "    # ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [\n",
    "        transform(image=np.array(image))[\"image\"] for image in examples[\"image\"]\n",
    "    ]\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'You have to pass data to augmentations as named arguments, for example: aug(image=image)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# verify the transformation\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(dataset[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# augmented_image = transform(image=image)[\"image\"]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# plt.imshow(augmented_image)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhinowo/Documents/LearningProject/hfSeries/Image/Classification/ft-classification.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2788\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2786\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2787\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2788\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2789\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   2790\u001b[0m )\n\u001b[1;32m   2791\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[1;32m    630\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:396\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable, query_type: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_row(pa_table)\n\u001b[1;32m    397\u001b[0m     \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    398\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:485\u001b[0m, in \u001b[0;36mCustomFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_row\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m--> 485\u001b[0m     formatted_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_batch(pa_table)\n\u001b[1;32m    486\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m         \u001b[39mreturn\u001b[39;00m _unnest(formatted_batch)\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:515\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    513\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_arrow_extractor()\u001b[39m.\u001b[39mextract_batch(pa_table)\n\u001b[1;32m    514\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_features_decoder\u001b[39m.\u001b[39mdecode_batch(batch)\n\u001b[0;32m--> 515\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(batch)\n",
      "File \u001b[0;32m~/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/albumentations/core/composition.py:193\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, force_apply: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mDict[\u001b[39mstr\u001b[39m, typing\u001b[39m.\u001b[39mAny]:\n\u001b[1;32m    192\u001b[0m     \u001b[39mif\u001b[39;00m args:\n\u001b[0;32m--> 193\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to pass data to augmentations as named arguments, for example: aug(image=image)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_check_args:\n\u001b[1;32m    195\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_args(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'You have to pass data to augmentations as named arguments, for example: aug(image=image)'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# verify the transformation\n",
    "plt.imshow(dataset[\"train\"][0][\"pixel_values\"])\n",
    "# augmented_image = transform(image=image)[\"image\"]\n",
    "# plt.imshow(augmented_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
