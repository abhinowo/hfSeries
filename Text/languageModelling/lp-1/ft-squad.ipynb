{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This is my first time working on a Question-Answering system in NLP. Most of this code was obtained by referencing the work of [pallavrajsahoo]((https://github.com/pallavrajsahoo/Question-Answering-System-with-SQuAD-dataset)). A big shoutout to him for helping me understand what to do with this dataset! It's possible that by the time you're reading my notebook, it won't be perfectly finished. I'll do my best to keep updating the notebook until it's complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Description About the Datasest\n",
    "\n",
    "**Stanford Question Answering Dataset (SQuAD)** is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n",
    "\n",
    "1. [tf-link](https://www.tensorflow.org/datasets/catalog/squad) \n",
    "2. [officialHomepage](https://rajpurkar.github.io/SQuAD-explorer/) \n",
    "3. [paperDoc](https://paperswithcode.com/dataset/squad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinowo/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys, random, pickle, json\n",
    "from datasets import load_dataset, list_datasets\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "nltk.download(\"stopwords\", quiet = True)\n",
    "nltk.download(\"wordnet\", quiet = True)\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet = True)\n",
    "nltk.download(\"punkt\", quiet = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 27 14:13:49 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P5               6W /  50W |    674MiB /  8188MiB |     21%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1075      G   /usr/lib/xorg/Xorg                          263MiB |\n",
      "|    0   N/A  N/A      1623      G   cinnamon                                    112MiB |\n",
      "|    0   N/A  N/A      2375      G   ...75959784,7019215664762331727,262144      134MiB |\n",
      "|    0   N/A  N/A      7787      G   ...sion,SpareRendererForSitePerProcess      119MiB |\n",
      "|    0   N/A  N/A     15748      G   ...ures=SpareRendererForSitePerProcess       32MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch .cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29371/3844060883.py:1: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
      "  dataset = list_datasets()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73461"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list_datasets()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(actual, expected):\n",
    "    assert actual == expected, actual\n",
    "\n",
    "def check_approx(actual, expected):\n",
    "    assert np.allclose(actual, expected), actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dont mind this **squad_v2**. ill try from squad dataset first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset2 = load_dataset(\"squad_v2\")\n",
    "squad_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>{'text': ['2003'], 'answer_start': [526]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>{'text': ['Houston, Texas'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>{'text': ['late 1990s'], 'answer_start': [276]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    title  \\\n",
       "0  56be85543aeaaa14008c9063  Beyoncé   \n",
       "1  56be85543aeaaa14008c9065  Beyoncé   \n",
       "2  56be85543aeaaa14008c9066  Beyoncé   \n",
       "3  56bf6b0f3aeaaa14008c9601  Beyoncé   \n",
       "4  56bf6b0f3aeaaa14008c9602  Beyoncé   \n",
       "\n",
       "                                             context  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "\n",
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['in the late 1990s'], 'answer_start'...  \n",
       "1  {'text': ['singing and dancing'], 'answer_star...  \n",
       "2          {'text': ['2003'], 'answer_start': [526]}  \n",
       "3  {'text': ['Houston, Texas'], 'answer_start': [...  \n",
       "4    {'text': ['late 1990s'], 'answer_start': [276]}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(squad_dataset2[\"train\"])\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset = load_dataset('squad')\n",
    "squad_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the dataset into a dataframe\n",
    "\n",
    "df = pd.DataFrame(squad_dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  \n",
       "0               Saint Bernadette Soubirous           515  \n",
       "1                a copper statue of Christ           188  \n",
       "2                        the Main Building           279  \n",
       "3  a Marian place of prayer and reflection           381  \n",
       "4       a golden statue of the Virgin Mary            92  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean answers column\n",
    "\n",
    "df['answer_start'] = df['answers'].apply(lambda x: x['answer_start'][0])\n",
    "df['answers'] = df['answers'].apply(lambda x: x['text'][0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['context'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  \n",
       "0               Saint Bernadette Soubirous           515  \n",
       "1                a copper statue of Christ           188  \n",
       "2                        the Main Building           279  \n",
       "3  a Marian place of prayer and reflection           381  \n",
       "4       a golden statue of the Virgin Mary            92  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop id column\n",
    "\n",
    "df.drop('id', axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87599 entries, 0 to 87598\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         87599 non-null  object\n",
      " 1   context       87599 non-null  object\n",
      " 2   question      87599 non-null  object\n",
      " 3   answers       87599 non-null  object\n",
      " 4   answer_start  87599 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87599 entries, 0 to 87598\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         87599 non-null  object\n",
      " 1   context       87599 non-null  object\n",
      " 2   question      87599 non-null  object\n",
      " 3   answers       87599 non-null  object\n",
      " 4   answer_start  87599 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# turn title to string, context to string, question to string, answers to string and answer_start to int\n",
    "\n",
    "df['title'] = df['title'].astype(str)\n",
    "df['context'] = df['context'].astype(str)\n",
    "df['question'] = df['question'].astype(str)\n",
    "df['answers'] = df['answers'].astype(str)\n",
    "df['answer_start'] = df['answer_start'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': 'Saint Bernadette Soubirous',\n",
       " 'answer_start': 515}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying check similarity between two sentences - test\n",
    "\n",
    "def jaccard_similarity(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "jaccard_similarity(\"My name is John\", \"John is my name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \n",
       "0               Saint Bernadette Soubirous           515            0.000000  \n",
       "1                a copper statue of Christ           188            0.071429  \n",
       "2                        the Main Building           279            0.066667  \n",
       "3  a Marian place of prayer and reflection           381            0.000000  \n",
       "4       a golden statue of the Virgin Mary            92            0.125000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement jaccard similarity between question and answer\n",
    "\n",
    "def jaccard_similarity(str1, str2):\n",
    "    a = set(str1.lower().split())\n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "df['jaccard_similarity'] = df.apply(lambda x: jaccard_similarity(x['question'], x['answers']), axis = 1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16820</th>\n",
       "      <td>Nanjing</td>\n",
       "      <td>Nanjing ( listen; Chinese: 南京, \"Southern Capit...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16821</th>\n",
       "      <td>Nanjing</td>\n",
       "      <td>Nanjing ( listen; Chinese: 南京, \"Southern Capit...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16822</th>\n",
       "      <td>Nanjing</td>\n",
       "      <td>Nanjing ( listen; Chinese: 南京, \"Southern Capit...</td>\n",
       "      <td>v</td>\n",
       "      <td>v</td>\n",
       "      <td>108</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30525</th>\n",
       "      <td>Federal_Bureau_of_Investigation</td>\n",
       "      <td>In response to organized crime, on August 25, ...</td>\n",
       "      <td>Is the RICO Act still used today?</td>\n",
       "      <td>The RICO Act is still used</td>\n",
       "      <td>939</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55172</th>\n",
       "      <td>FA_Cup</td>\n",
       "      <td>Following the 1914–15 edition, the competition...</td>\n",
       "      <td>Was competition suspended due to the first wor...</td>\n",
       "      <td>competition was suspended due to the First Wor...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14006</th>\n",
       "      <td>Internet_service_provider</td>\n",
       "      <td>Network hardware, software and specifications,...</td>\n",
       "      <td>Is a tradeoff between efficiency and cost poss...</td>\n",
       "      <td>A tradeoff between cost and efficiency is poss...</td>\n",
       "      <td>214</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48862</th>\n",
       "      <td>Somerset</td>\n",
       "      <td>Until the 1960s the piers at Weston-super-Mare...</td>\n",
       "      <td>What is the shortest pier in the UK</td>\n",
       "      <td>The pier at Burnham-on-Sea is the shortest pie...</td>\n",
       "      <td>417</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77599</th>\n",
       "      <td>Premier_League</td>\n",
       "      <td>Due to insistence by the International Federat...</td>\n",
       "      <td>What was the number of clubs reduced to in 1995.</td>\n",
       "      <td>the number of clubs was reduced to 20 in 1995</td>\n",
       "      <td>191</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55287</th>\n",
       "      <td>FA_Cup</td>\n",
       "      <td>Seven clubs have won the FA Cup as part of a L...</td>\n",
       "      <td>How many clubs have won the fa cup as part of ...</td>\n",
       "      <td>Seven clubs have won the FA Cup as part of a L...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57999</th>\n",
       "      <td>Political_party</td>\n",
       "      <td>In a nonpartisan system, no official political...</td>\n",
       "      <td>Do official political parties exist in a nonpa...</td>\n",
       "      <td>In a nonpartisan system, no official political...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "16820                          Nanjing   \n",
       "16821                          Nanjing   \n",
       "16822                          Nanjing   \n",
       "30525  Federal_Bureau_of_Investigation   \n",
       "55172                           FA_Cup   \n",
       "14006        Internet_service_provider   \n",
       "48862                         Somerset   \n",
       "77599                   Premier_League   \n",
       "55287                           FA_Cup   \n",
       "57999                  Political_party   \n",
       "\n",
       "                                                 context  \\\n",
       "16820  Nanjing ( listen; Chinese: 南京, \"Southern Capit...   \n",
       "16821  Nanjing ( listen; Chinese: 南京, \"Southern Capit...   \n",
       "16822  Nanjing ( listen; Chinese: 南京, \"Southern Capit...   \n",
       "30525  In response to organized crime, on August 25, ...   \n",
       "55172  Following the 1914–15 edition, the competition...   \n",
       "14006  Network hardware, software and specifications,...   \n",
       "48862  Until the 1960s the piers at Weston-super-Mare...   \n",
       "77599  Due to insistence by the International Federat...   \n",
       "55287  Seven clubs have won the FA Cup as part of a L...   \n",
       "57999  In a nonpartisan system, no official political...   \n",
       "\n",
       "                                                question  \\\n",
       "16820                                                  n   \n",
       "16821                                                  b   \n",
       "16822                                                  v   \n",
       "30525                  Is the RICO Act still used today?   \n",
       "55172  Was competition suspended due to the first wor...   \n",
       "14006  Is a tradeoff between efficiency and cost poss...   \n",
       "48862               What is the shortest pier in the UK    \n",
       "77599   What was the number of clubs reduced to in 1995.   \n",
       "55287  How many clubs have won the fa cup as part of ...   \n",
       "57999  Do official political parties exist in a nonpa...   \n",
       "\n",
       "                                                 answers  answer_start  \\\n",
       "16820                                                  n             2   \n",
       "16821                                                  b           144   \n",
       "16822                                                  v           108   \n",
       "30525                         The RICO Act is still used           939   \n",
       "55172  competition was suspended due to the First Wor...            35   \n",
       "14006  A tradeoff between cost and efficiency is poss...           214   \n",
       "48862  The pier at Burnham-on-Sea is the shortest pie...           417   \n",
       "77599      the number of clubs was reduced to 20 in 1995           191   \n",
       "55287  Seven clubs have won the FA Cup as part of a L...             0   \n",
       "57999  In a nonpartisan system, no official political...             0   \n",
       "\n",
       "       jaccard_similarity  \n",
       "16820            1.000000  \n",
       "16821            1.000000  \n",
       "16822            1.000000  \n",
       "30525            0.857143  \n",
       "55172            0.800000  \n",
       "14006            0.777778  \n",
       "48862            0.666667  \n",
       "77599            0.666667  \n",
       "55287            0.647059  \n",
       "57999            0.636364  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by= 'jaccard_similarity',ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Nanjing',\n",
       " 'context': 'Nanjing ( listen; Chinese: 南京, \"Southern Capital\") is the city situated in the heartland of lower Yangtze River region in China, which has long been a major centre of culture, education, research, politics, economy, transport networks and tourism. It is the capital city of Jiangsu province of People\\'s Republic of China and the second largest city in East China, with a total population of 8,216,100, and legally the capital of Republic of China which lost the mainland during the civil war. The city whose name means \"Southern Capital\" has a prominent place in Chinese history and culture, having served as the capitals of various Chinese dynasties, kingdoms and republican governments dating from the 3rd century AD to 1949. Prior to the advent of pinyin romanization, Nanjing\\'s city name was spelled as Nanking or Nankin. Nanjing has a number of other names, and some historical names are now used as names of districts of the city, and among them there is the name Jiangning (江寧), whose former character Jiang (江, River) is the former part of the name Jiangsu and latter character Ning (寧, simplified form 宁, Peace) is the short name of Nanjing. When being the capital of a state, for instance, ROC, Jing (京) is adopted as the abbreviation of Nanjing. Although as a city located in southern part of China becoming Chinese national capital as early as in Jin dynasty, the name Nanjing was designated to the city in Ming dynasty, about a thousand years later. Nanjing is particularly known as Jinling (金陵, literally meaning Gold Mountain) and the old name has been used since the Warring States Period in Zhou Dynasty.',\n",
       " 'question': 'n',\n",
       " 'answers': 'n',\n",
       " 'answer_start': 2,\n",
       " 'jaccard_similarity': 1.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check why is there some weird value in answer and question\n",
    "\n",
    "df.iloc[16820].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54923</th>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>A number of medications are being studied for ...</td>\n",
       "      <td>Despite FDA approval, how much more likely to ...</td>\n",
       "      <td>five times</td>\n",
       "      <td>444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54934</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action is a subject of controversy...</td>\n",
       "      <td>What do critics of affirmative action believe ...</td>\n",
       "      <td>achievement</td>\n",
       "      <td>961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54933</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action is a subject of controversy...</td>\n",
       "      <td>In which time period did discrimination polici...</td>\n",
       "      <td>Reconstruction Era</td>\n",
       "      <td>557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54932</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action is a subject of controversy...</td>\n",
       "      <td>What case determined that some implementation ...</td>\n",
       "      <td>Gratz v. Bollinger</td>\n",
       "      <td>321</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54931</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action is a subject of controversy...</td>\n",
       "      <td>Having quotas regarding admissions or employme...</td>\n",
       "      <td>reverse</td>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54930</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action is a subject of controversy...</td>\n",
       "      <td>What is another example aside from racial quot...</td>\n",
       "      <td>gender quotas</td>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54927</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action in the United States tends ...</td>\n",
       "      <td>Affirmative action attempts to ask institution...</td>\n",
       "      <td>racial minorities</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54926</th>\n",
       "      <td>Affirmative_action_in_the_United_States</td>\n",
       "      <td>Affirmative action in the United States tends ...</td>\n",
       "      <td>Outside of employment, what is the other main ...</td>\n",
       "      <td>education</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54925</th>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>A number of medications are being studied for ...</td>\n",
       "      <td>What type of publication has put out articles ...</td>\n",
       "      <td>medical journal</td>\n",
       "      <td>529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54924</th>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>A number of medications are being studied for ...</td>\n",
       "      <td>Opposition to the use of bedaquiline think wha...</td>\n",
       "      <td>physicians</td>\n",
       "      <td>694</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "54923                             Tuberculosis   \n",
       "54934  Affirmative_action_in_the_United_States   \n",
       "54933  Affirmative_action_in_the_United_States   \n",
       "54932  Affirmative_action_in_the_United_States   \n",
       "54931  Affirmative_action_in_the_United_States   \n",
       "54930  Affirmative_action_in_the_United_States   \n",
       "54927  Affirmative_action_in_the_United_States   \n",
       "54926  Affirmative_action_in_the_United_States   \n",
       "54925                             Tuberculosis   \n",
       "54924                             Tuberculosis   \n",
       "\n",
       "                                                 context  \\\n",
       "54923  A number of medications are being studied for ...   \n",
       "54934  Affirmative action is a subject of controversy...   \n",
       "54933  Affirmative action is a subject of controversy...   \n",
       "54932  Affirmative action is a subject of controversy...   \n",
       "54931  Affirmative action is a subject of controversy...   \n",
       "54930  Affirmative action is a subject of controversy...   \n",
       "54927  Affirmative action in the United States tends ...   \n",
       "54926  Affirmative action in the United States tends ...   \n",
       "54925  A number of medications are being studied for ...   \n",
       "54924  A number of medications are being studied for ...   \n",
       "\n",
       "                                                question             answers  \\\n",
       "54923  Despite FDA approval, how much more likely to ...          five times   \n",
       "54934  What do critics of affirmative action believe ...         achievement   \n",
       "54933  In which time period did discrimination polici...  Reconstruction Era   \n",
       "54932  What case determined that some implementation ...  Gratz v. Bollinger   \n",
       "54931  Having quotas regarding admissions or employme...             reverse   \n",
       "54930  What is another example aside from racial quot...       gender quotas   \n",
       "54927  Affirmative action attempts to ask institution...   racial minorities   \n",
       "54926  Outside of employment, what is the other main ...           education   \n",
       "54925  What type of publication has put out articles ...     medical journal   \n",
       "54924  Opposition to the use of bedaquiline think wha...          physicians   \n",
       "\n",
       "       answer_start  jaccard_similarity  \n",
       "54923           444                 0.0  \n",
       "54934           961                 0.0  \n",
       "54933           557                 0.0  \n",
       "54932           321                 0.0  \n",
       "54931           192                 0.0  \n",
       "54930           118                 0.0  \n",
       "54927           146                 0.0  \n",
       "54926            73                 0.0  \n",
       "54925           529                 0.0  \n",
       "54924           694                 0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by= 'jaccard_similarity',ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Tuberculosis',\n",
       " 'context': \"A number of medications are being studied for multi drug resistant tuberculosis including: bedaquiline and delamanid. Bedaquiline received U.S. Food and Drug Administration (FDA) approval in late 2012. The safety and effectiveness of these new agents are still uncertain, because they are based on the results of a relatively small studies. However, existing data suggest that patients taking bedaquiline in addition to standard TB therapy are five times more likely to die than those without the new drug, which has resulted in medical journal articles raising health policy questions about why the FDA approved the drug and whether financial ties to the company making bedaquiline influenced physicians' support for its use \",\n",
       " 'question': 'Despite FDA approval, how much more likely to die are patients who take bedaquiline in addition to the standard TB regimen?',\n",
       " 'answers': 'five times',\n",
       " 'answer_start': 444,\n",
       " 'jaccard_similarity': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see why it got such a low score\n",
    "\n",
    "df.iloc[54923].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_similarity(str1, str2):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([str1, str2])\n",
    "    return ((tfidf_matrix * tfidf_matrix.T).A)[0,1]\n",
    "\n",
    "tfidf_similarity(\"My name is John\", \"John is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinowo/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/abhinowo/Documents/LearningProject/hfSeries/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                tokenizer=&lt;function word_tokenize at 0x7f06419fdb40&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                tokenizer=&lt;function word_tokenize at 0x7f06419fdb40&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=10000, ngram_range=(1, 2),\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function word_tokenize at 0x7f06419fdb40>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    tokenizer = nltk.word_tokenize,\n",
    "    stop_words = stopwords.words('english'),\n",
    "    # lowercase = True\n",
    "    ngram_range = (1, 2),\n",
    "    max_features = 10000,\n",
    ")\n",
    "\n",
    "tfidf_vectorizer.fit(df['context'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>{'text': ['Carolina Panthers', 'Carolina Panth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>{'text': ['Santa Clara, California', 'Levi's S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>{'text': ['gold', 'gold', 'gold'], 'answer_sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id          title  \\\n",
       "0  56be4db0acb8001400a502ec  Super_Bowl_50   \n",
       "1  56be4db0acb8001400a502ed  Super_Bowl_50   \n",
       "2  56be4db0acb8001400a502ee  Super_Bowl_50   \n",
       "3  56be4db0acb8001400a502ef  Super_Bowl_50   \n",
       "4  56be4db0acb8001400a502f0  Super_Bowl_50   \n",
       "\n",
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...   \n",
       "1  Which NFL team represented the NFC at Super Bo...   \n",
       "2                Where did Super Bowl 50 take place?   \n",
       "3                  Which NFL team won Super Bowl 50?   \n",
       "4  What color was used to emphasize the 50th anni...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Denver Broncos', 'Denver Broncos', ...  \n",
       "1  {'text': ['Carolina Panthers', 'Carolina Panth...  \n",
       "2  {'text': ['Santa Clara, California', 'Levi's S...  \n",
       "3  {'text': ['Denver Broncos', 'Denver Broncos', ...  \n",
       "4  {'text': ['gold', 'gold', 'gold'], 'answer_sta...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the dataset into a dataframe\n",
    "\n",
    "df_val = pd.DataFrame(squad_dataset['validation'])\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10570 entries, 0 to 10569\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         10570 non-null  object\n",
      " 1   context       10570 non-null  object\n",
      " 2   question      10570 non-null  object\n",
      " 3   answers       10570 non-null  object\n",
      " 4   answer_start  10570 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 413.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# do the same thing as we did for the train dataset\n",
    "\n",
    "df_val['answer_start'] = df_val['answers'].apply(lambda x: x['answer_start'][0])\n",
    "df_val['answers'] = df_val['answers'].apply(lambda x: x['text'][0])\n",
    "df_val.drop('id', axis = 1, inplace = True)\n",
    "df_val['title'] = df_val['title'].astype(str)\n",
    "df_val['context'] = df_val['context'].astype(str)\n",
    "df_val['question'] = df_val['question'].astype(str)\n",
    "df_val['answers'] = df_val['answers'].astype(str)\n",
    "df_val['answer_start'] = df_val['answer_start'].astype(int)\n",
    "df_val.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>gold</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the metric term less used than the New...</td>\n",
       "      <td>kilogram-force</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the kilogram-force sometimes reffered ...</td>\n",
       "      <td>kilopond</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>slug</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What seldom used term of a unit of force equal...</td>\n",
       "      <td>kip</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                            context  \\\n",
       "0      Super_Bowl_50  Super Bowl 50 was an American football game to...   \n",
       "1      Super_Bowl_50  Super Bowl 50 was an American football game to...   \n",
       "2      Super_Bowl_50  Super Bowl 50 was an American football game to...   \n",
       "3      Super_Bowl_50  Super Bowl 50 was an American football game to...   \n",
       "4      Super_Bowl_50  Super Bowl 50 was an American football game to...   \n",
       "...              ...                                                ...   \n",
       "10565          Force  The pound-force has a metric counterpart, less...   \n",
       "10566          Force  The pound-force has a metric counterpart, less...   \n",
       "10567          Force  The pound-force has a metric counterpart, less...   \n",
       "10568          Force  The pound-force has a metric counterpart, less...   \n",
       "10569          Force  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                question  \\\n",
       "0      Which NFL team represented the AFC at Super Bo...   \n",
       "1      Which NFL team represented the NFC at Super Bo...   \n",
       "2                    Where did Super Bowl 50 take place?   \n",
       "3                      Which NFL team won Super Bowl 50?   \n",
       "4      What color was used to emphasize the 50th anni...   \n",
       "...                                                  ...   \n",
       "10565  What is the metric term less used than the New...   \n",
       "10566  What is the kilogram-force sometimes reffered ...   \n",
       "10567  What is a very seldom used unit of mass in the...   \n",
       "10568  What seldom used term of a unit of force equal...   \n",
       "10569  What is the seldom used force unit equal to on...   \n",
       "\n",
       "                       answers  answer_start  \n",
       "0               Denver Broncos           177  \n",
       "1            Carolina Panthers           249  \n",
       "2      Santa Clara, California           403  \n",
       "3               Denver Broncos           177  \n",
       "4                         gold           488  \n",
       "...                        ...           ...  \n",
       "10565           kilogram-force            82  \n",
       "10566                 kilopond           114  \n",
       "10567                     slug           274  \n",
       "10568                      kip           712  \n",
       "10569                   sthène           665  \n",
       "\n",
       "[10570 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The city has two universities — Newcastle University and Northumbria University. Newcastle University has its origins in the School of Medicine and Surgery, established in 1834 and became independent from Durham University on 1 August 1963 to form the University of Newcastle upon Tyne. Newcastle University is now one of the UK\\'s leading international universities. It won the coveted Sunday Times University of the Year award in 2000. Northumbria University has its origins in the Newcastle Polytechnic, established in 1969 and became the University of Northumbria at Newcastle in 1992 as part of the UK-wide process in which polytechnics became new universities. Northumbria University was voted \\'Best New University\\' by The Times Good University Guide 2005 and also won a much coveted company award of the \"Most IT enabled organisation\" (in the UK), by the IT industry magazine Computing.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test tfidf vectorizer\n",
    "\n",
    "test_context = df_val['context']\n",
    "tfid_vector_val = tfidf_vectorizer.transform(test_context)\n",
    "\n",
    "# find the most similar context to the question\n",
    "\n",
    "def find_similar_question(question):\n",
    "    tfid_vector_question = tfidf_vectorizer.transform([question])\n",
    "    similarity = np.dot(tfid_vector_val, tfid_vector_question.T).toarray()\n",
    "    return similarity.argmax()\n",
    "\n",
    "find_similar_question(\"What is the name of the university?\")\n",
    "df_val['context'].loc[find_similar_question(\"What is the name of the university?\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(…)cased/resolve/main/tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 216kB/s]\n",
      "(…)bert-base-uncased/resolve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 71.9MB/s]\n",
      "(…)base-uncased/resolve/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 34.2MB/s]\n",
      "(…)rt-base-uncased/resolve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 5.99MB/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenization for bert\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>tokenized_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \\\n",
       "0               Saint Bernadette Soubirous           515            0.000000   \n",
       "1                a copper statue of Christ           188            0.071429   \n",
       "2                        the Main Building           279            0.066667   \n",
       "3  a Marian place of prayer and reflection           381            0.000000   \n",
       "4       a golden statue of the Virgin Mary            92            0.125000   \n",
       "\n",
       "                                   tokenized_context  \n",
       "0  [architectural, ##ly, ,, the, school, has, a, ...  \n",
       "1  [architectural, ##ly, ,, the, school, has, a, ...  \n",
       "2  [architectural, ##ly, ,, the, school, has, a, ...  \n",
       "3  [architectural, ##ly, ,, the, school, has, a, ...  \n",
       "4  [architectural, ##ly, ,, the, school, has, a, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize the context\n",
    "\n",
    "def tokenize_context(context):\n",
    "    return tokenizer.tokenize(context)\n",
    "\n",
    "df['tokenized_context'] = df['context'].apply(lambda x: tokenize_context(x))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>tokenized_context</th>\n",
       "      <th>tokenized_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[to, whom, did, the, virgin, mary, allegedly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, in, front, of, the, notre, dame, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[the, basilica, of, the, sacred, heart, at, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, the, gr, ##otto, at, notre, dame, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, sits, on, top, of, the, main, building,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \\\n",
       "0               Saint Bernadette Soubirous           515            0.000000   \n",
       "1                a copper statue of Christ           188            0.071429   \n",
       "2                        the Main Building           279            0.066667   \n",
       "3  a Marian place of prayer and reflection           381            0.000000   \n",
       "4       a golden statue of the Virgin Mary            92            0.125000   \n",
       "\n",
       "                                   tokenized_context  \\\n",
       "0  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "1  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "2  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "3  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "4  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "\n",
       "                                  tokenized_question  \n",
       "0  [to, whom, did, the, virgin, mary, allegedly, ...  \n",
       "1  [what, is, in, front, of, the, notre, dame, ma...  \n",
       "2  [the, basilica, of, the, sacred, heart, at, no...  \n",
       "3    [what, is, the, gr, ##otto, at, notre, dame, ?]  \n",
       "4  [what, sits, on, top, of, the, main, building,...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after tokenize the context, we need to tokenize the question\n",
    "\n",
    "def tokenize_question(question):\n",
    "    return tokenizer.tokenize(question)\n",
    "\n",
    "df['tokenized_question'] = df['question'].apply(lambda x: tokenize_question(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>tokenized_context</th>\n",
       "      <th>tokenized_question</th>\n",
       "      <th>tokenized_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[to, whom, did, the, virgin, mary, allegedly, ...</td>\n",
       "      <td>[saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, in, front, of, the, notre, dame, ma...</td>\n",
       "      <td>[a, copper, statue, of, christ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[the, basilica, of, the, sacred, heart, at, no...</td>\n",
       "      <td>[the, main, building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, the, gr, ##otto, at, notre, dame, ?]</td>\n",
       "      <td>[a, marian, place, of, prayer, and, reflection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, sits, on, top, of, the, main, building,...</td>\n",
       "      <td>[a, golden, statue, of, the, virgin, mary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \\\n",
       "0               Saint Bernadette Soubirous           515            0.000000   \n",
       "1                a copper statue of Christ           188            0.071429   \n",
       "2                        the Main Building           279            0.066667   \n",
       "3  a Marian place of prayer and reflection           381            0.000000   \n",
       "4       a golden statue of the Virgin Mary            92            0.125000   \n",
       "\n",
       "                                   tokenized_context  \\\n",
       "0  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "1  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "2  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "3  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "4  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "\n",
       "                                  tokenized_question  \\\n",
       "0  [to, whom, did, the, virgin, mary, allegedly, ...   \n",
       "1  [what, is, in, front, of, the, notre, dame, ma...   \n",
       "2  [the, basilica, of, the, sacred, heart, at, no...   \n",
       "3    [what, is, the, gr, ##otto, at, notre, dame, ?]   \n",
       "4  [what, sits, on, top, of, the, main, building,...   \n",
       "\n",
       "                                    tokenized_answer  \n",
       "0  [saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...  \n",
       "1                    [a, copper, statue, of, christ]  \n",
       "2                              [the, main, building]  \n",
       "3    [a, marian, place, of, prayer, and, reflection]  \n",
       "4         [a, golden, statue, of, the, virgin, mary]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to tokenize the answer\n",
    "\n",
    "def tokenize_answer(answer):\n",
    "    return tokenizer.tokenize(answer)\n",
    "\n",
    "df['tokenized_answer'] = df['answers'].apply(lambda x: tokenize_answer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>tokenized_context</th>\n",
       "      <th>tokenized_question</th>\n",
       "      <th>tokenized_answer</th>\n",
       "      <th>answer_start_tokenized</th>\n",
       "      <th>answer_end_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[to, whom, did, the, virgin, mary, allegedly, ...</td>\n",
       "      <td>[saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...</td>\n",
       "      <td>113</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, in, front, of, the, notre, dame, ma...</td>\n",
       "      <td>[a, copper, statue, of, christ]</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[the, basilica, of, the, sacred, heart, at, no...</td>\n",
       "      <td>[the, main, building]</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, the, gr, ##otto, at, notre, dame, ?]</td>\n",
       "      <td>[a, marian, place, of, prayer, and, reflection]</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, sits, on, top, of, the, main, building,...</td>\n",
       "      <td>[a, golden, statue, of, the, virgin, mary]</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \\\n",
       "0               Saint Bernadette Soubirous           515            0.000000   \n",
       "1                a copper statue of Christ           188            0.071429   \n",
       "2                        the Main Building           279            0.066667   \n",
       "3  a Marian place of prayer and reflection           381            0.000000   \n",
       "4       a golden statue of the Virgin Mary            92            0.125000   \n",
       "\n",
       "                                   tokenized_context  \\\n",
       "0  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "1  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "2  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "3  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "4  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "\n",
       "                                  tokenized_question  \\\n",
       "0  [to, whom, did, the, virgin, mary, allegedly, ...   \n",
       "1  [what, is, in, front, of, the, notre, dame, ma...   \n",
       "2  [the, basilica, of, the, sacred, heart, at, no...   \n",
       "3    [what, is, the, gr, ##otto, at, notre, dame, ?]   \n",
       "4  [what, sits, on, top, of, the, main, building,...   \n",
       "\n",
       "                                    tokenized_answer  answer_start_tokenized  \\\n",
       "0  [saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...                     113   \n",
       "1                    [a, copper, statue, of, christ]                      39   \n",
       "2                              [the, main, building]                      11   \n",
       "3    [a, marian, place, of, prayer, and, reflection]                      84   \n",
       "4         [a, golden, statue, of, the, virgin, mary]                      19   \n",
       "\n",
       "   answer_end_tokenized  \n",
       "0                   121  \n",
       "1                    44  \n",
       "2                    14  \n",
       "3                    91  \n",
       "4                    26  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see that the tokenized answer is not the same as the answer, so we need to find the answer in the tokenized context\n",
    "\n",
    "def find_answer_in_tokenized_context(tokenized_context, tokenized_answer):\n",
    "    for i in range(len(tokenized_context)):\n",
    "        if tokenized_context[i:i+len(tokenized_answer)] == tokenized_answer:\n",
    "            return i, i+len(tokenized_answer)\n",
    "    return -1, -1\n",
    "\n",
    "df['answer_start_tokenized'], df['answer_end_tokenized'] = zip(*df.apply(lambda x: find_answer_in_tokenized_context(x['tokenized_context'], x['tokenized_answer']), axis = 1))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "      <th>tokenized_context</th>\n",
       "      <th>tokenized_question</th>\n",
       "      <th>tokenized_answer</th>\n",
       "      <th>answer_start_tokenized</th>\n",
       "      <th>answer_end_tokenized</th>\n",
       "      <th>score</th>\n",
       "      <th>score_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[to, whom, did, the, virgin, mary, allegedly, ...</td>\n",
       "      <td>[saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...</td>\n",
       "      <td>113</td>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>0.056337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, in, front, of, the, notre, dame, ma...</td>\n",
       "      <td>[a, copper, statue, of, christ]</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[the, basilica, of, the, sacred, heart, at, no...</td>\n",
       "      <td>[the, main, building]</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.478603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, is, the, gr, ##otto, at, notre, dame, ?]</td>\n",
       "      <td>[a, marian, place, of, prayer, and, reflection]</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>0.221936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>[architectural, ##ly, ,, the, school, has, a, ...</td>\n",
       "      <td>[what, sits, on, top, of, the, main, building,...</td>\n",
       "      <td>[a, golden, statue, of, the, virgin, mary]</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.514849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0  University_of_Notre_Dame   \n",
       "1  University_of_Notre_Dame   \n",
       "2  University_of_Notre_Dame   \n",
       "3  University_of_Notre_Dame   \n",
       "4  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                   answers  answer_start  jaccard_similarity  \\\n",
       "0               Saint Bernadette Soubirous           515            0.000000   \n",
       "1                a copper statue of Christ           188            0.071429   \n",
       "2                        the Main Building           279            0.066667   \n",
       "3  a Marian place of prayer and reflection           381            0.000000   \n",
       "4       a golden statue of the Virgin Mary            92            0.125000   \n",
       "\n",
       "                                   tokenized_context  \\\n",
       "0  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "1  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "2  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "3  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "4  [architectural, ##ly, ,, the, school, has, a, ...   \n",
       "\n",
       "                                  tokenized_question  \\\n",
       "0  [to, whom, did, the, virgin, mary, allegedly, ...   \n",
       "1  [what, is, in, front, of, the, notre, dame, ma...   \n",
       "2  [the, basilica, of, the, sacred, heart, at, no...   \n",
       "3    [what, is, the, gr, ##otto, at, notre, dame, ?]   \n",
       "4  [what, sits, on, top, of, the, main, building,...   \n",
       "\n",
       "                                    tokenized_answer  answer_start_tokenized  \\\n",
       "0  [saint, bern, ##ade, ##tte, so, ##ub, ##iro, #...                     113   \n",
       "1                    [a, copper, statue, of, christ]                      39   \n",
       "2                              [the, main, building]                      11   \n",
       "3    [a, marian, place, of, prayer, and, reflection]                      84   \n",
       "4         [a, golden, statue, of, the, virgin, mary]                      19   \n",
       "\n",
       "   answer_end_tokenized  score  score_prediction  \n",
       "0                   121      8          0.056337  \n",
       "1                    44      5          0.219739  \n",
       "2                    14      3          0.478603  \n",
       "3                    91      7          0.221936  \n",
       "4                    26      7          0.514849  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the score prediction for the context and answer\n",
    "\n",
    "def find_score_prediction(context, answer):\n",
    "    return tfidf_similarity(context, answer)\n",
    "\n",
    "df['score_prediction'] = df.apply(lambda x: find_score_prediction(x['context'], x['answers']), axis = 1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
